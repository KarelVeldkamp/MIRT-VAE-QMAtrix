{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd08293",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from data import *\n",
    "from helpers import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "\n",
    "# set working directory to source file location\n",
    "abspath = os.path.abspath(__file__)\n",
    "dname = os.path.dirname(abspath)\n",
    "os.chdir(dname)\n",
    "\n",
    "# set device to gpu if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# load configurations\n",
    "with open(\"./config.yml\", \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "    cfg = cfg['configs']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9724008a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate data\n",
    "if cfg['simulate']:\n",
    "    theta=np.random.normal(0,1,cfg['N']*cfg['mirt_dim']).reshape((cfg['N'], cfg['mirt_dim']))\n",
    "    Q = pd.read_csv(f'parameters/QMatrix{cfg[\"mirt_dim\"]}D.csv', header=None).values\n",
    "\n",
    "    a = np.random.uniform(.5, 2, Q.shape[0] * cfg['mirt_dim']).reshape((Q.shape[0], cfg['mirt_dim']))  # draw discrimination parameters from uniform distribution\n",
    "    a *= Q\n",
    "    b = np.linspace(-2, 2, Q.shape[0], endpoint=True)  # eqally spaced values between -2 and 2 for the difficulty\n",
    "    exponent = np.dot(theta, a.T) + b\n",
    "\n",
    "    prob = np.exp(exponent) / (1 + np.exp(exponent))\n",
    "    data = np.random.binomial(1, prob).astype(float)\n",
    "else:\n",
    "    data = pd.read_csv(f'./data/simulated/data_{cfg[\"mirt_dim\"]}_{cfg[\"iteration\"]}.csv', header=None, index_col=False).to_numpy()\n",
    "    a = pd.read_csv(f'./parameters/simulated/a_{cfg[\"mirt_dim\"]}_{cfg[\"iteration\"]}.csv', header=None, index_col=False).to_numpy()\n",
    "    b = pd.read_csv(f'./parameters/simulated/b_{cfg[\"mirt_dim\"]}_{cfg[\"iteration\"]}.csv', header=None, index_col=False).to_numpy()\n",
    "    theta = pd.read_csv(f'./parameters/simulated/theta_{cfg[\"mirt_dim\"]}_{cfg[\"iteration\"]}.csv', header=None, index_col=False).to_numpy()\n",
    "    Q = pd.read_csv(f'./parameters/QMatrix{cfg[\"mirt_dim\"]}D.csv', header=None).values\n",
    "\n",
    "# potentially save data to disk\n",
    "if cfg['save']:\n",
    "    np.savetxt(f'./data/simulated/data_{cfg[\"mirt_dim\"]}_{cfg[\"iteration\"]}.csv', data, delimiter=\",\")\n",
    "    np.savetxt(f'./parameters/simulated/a_{cfg[\"mirt_dim\"]}_{cfg[\"iteration\"]}.csv', a, delimiter=\",\")\n",
    "    np.savetxt(f'./parameters/simulated/b_{cfg[\"mirt_dim\"]}_{cfg[\"iteration\"]}.csv', b, delimiter=\",\")\n",
    "    np.savetxt(f'./parameters/simulated/theta_{cfg[\"mirt_dim\"]}_{cfg[\"iteration\"]}.csv', theta, delimiter=\",\")\n",
    "\n",
    "# introduce missingness\n",
    "np.random.seed(cfg['iteration'])\n",
    "indices = np.random.choice(data.shape[0]*data.shape[1], replace=False, size=int(data.shape[0]*data.shape[1]*cfg['missing_percentage']))\n",
    "data[np.unravel_index(indices, data.shape)] = float('nan')\n",
    "data = torch.Tensor(data)\n",
    "\n",
    "# X = pd.read_csv('./data/missing/data.csv', index_col=0).to_numpy()\n",
    "# a = pd.read_csv('./data/missing/a.csv', index_col=0).to_numpy()\n",
    "# theta = pd.read_csv('./data/missing/theta.csv', index_col=0).to_numpy()\n",
    "# d = pd.read_csv('./data/missing/d.csv', index_col=0).to_numpy()\n",
    "# Q = (a != 0).astype(int)\n",
    "\n",
    "\n",
    "# initialise model and optimizer\n",
    "logger = CSVLogger(\"logs\", name='simfit', version=0)\n",
    "trainer = Trainer(fast_dev_run=cfg['single_epoch_test_run'],\n",
    "                  max_epochs=cfg['max_epochs'],\n",
    "                  enable_checkpointing=False, \n",
    "                  logger=False, \n",
    "                  callbacks=[EarlyStopping(monitor='train_loss', min_delta=cfg['min_delta'], patience=cfg['patience'], mode='min')])\n",
    "\n",
    "if cfg['model'] == 'cvae':\n",
    "    dataset = SimDataset(data)\n",
    "    train_loader = DataLoader(dataset, batch_size=cfg['batch_size'], shuffle=False)\n",
    "    vae = CVAE(nitems=data.shape[1],\n",
    "               dataloader=train_loader,\n",
    "               latent_dims=cfg['mirt_dim'],\n",
    "               hidden_layer_size=cfg['hidden_layer_size'],\n",
    "               hidden_layer_size2=cfg['hidden_layer_size2'],\n",
    "               hidden_layer_size3=cfg['hidden_layer_size3'],\n",
    "               qm=Q,\n",
    "               learning_rate=cfg['learning_rate'],\n",
    "               batch_size=data.shape[0]\n",
    "\n",
    "    )\n",
    "elif cfg['model'] == 'idvae':\n",
    "    dataset = SimDataset(data)\n",
    "    train_loader = DataLoader(dataset, batch_size=cfg['batch_size'], shuffle=False)\n",
    "    vae = IDVAE(nitems=data.shape[1],\n",
    "               dataloader=train_loader,\n",
    "               latent_dims=cfg['mirt_dim'],\n",
    "               hidden_layer_size=cfg['hidden_layer_size2'],\n",
    "               hidden_layer_size2=cfg['hidden_layer_size3'],\n",
    "               qm=Q,\n",
    "               learning_rate=cfg['learning_rate'],\n",
    "               batch_size=data.shape[0]\n",
    "\n",
    "    )\n",
    "elif cfg['model'] == 'ivae':\n",
    "    vae = IVAE(nitems=data.shape[1],\n",
    "               data=data,\n",
    "               latent_dims=cfg['mirt_dim'],\n",
    "               hidden_layer_size=cfg['hidden_layer_size2'],\n",
    "               hidden_layer_size2=cfg['hidden_layer_size3'],\n",
    "               qm=Q,\n",
    "               learning_rate=cfg['learning_rate'],\n",
    "               batch_size=data.shape[0],#cfg['batch_size']\n",
    "               i_miss=indices,\n",
    "    )\n",
    "elif cfg['model'] == 'pvae':\n",
    "    dataset = PartialDataset(data)\n",
    "    train_loader = DataLoader(dataset, batch_size=cfg['batch_size'], shuffle=False)\n",
    "    vae = PVAE(dataloader=train_loader,\n",
    "               nitems=Q.shape[0],\n",
    "               learning_rate=cfg['learning_rate'],\n",
    "               batch_size=data.shape[0],\n",
    "               emb_dim=cfg['p_emb_dim'],\n",
    "               h_hidden_dim=cfg['p_hidden_dim'],\n",
    "               latent_dim=cfg['p_latent_dim'],\n",
    "               hidden_layer_dim=cfg['p_hidden_layer_dim'],\n",
    "               mirt_dim=cfg['mirt_dim'],\n",
    "               Q=Q,\n",
    "               beta=1\n",
    "    )\n",
    "elif cfg['model'] == 'iwae':\n",
    "    dataset = SimDataset(data)\n",
    "    train_loader = DataLoader(dataset, batch_size=cfg['batch_size'], shuffle=False)\n",
    "    vae = IWAE(nitems=data.shape[1],\n",
    "               dataloader=train_loader,\n",
    "               latent_dims=cfg['mirt_dim'],\n",
    "               hidden_layer_size=cfg['hidden_layer_size'],\n",
    "               hidden_layer_size2=cfg['hidden_layer_size2'],\n",
    "               hidden_layer_size3=cfg['hidden_layer_size3'],\n",
    "               qm=Q,\n",
    "               learning_rate=cfg['learning_rate'],\n",
    "               batch_size=data.shape[0],\n",
    "               n_samples=cfg['n_iw_samples']\n",
    "    )\n",
    "elif cfg['model'] == 'vae':\n",
    "    dataset = SimDataset(data)\n",
    "    train_loader = DataLoader(dataset, batch_size=cfg['batch_size'], shuffle=False)\n",
    "    vae = VAE(nitems=data.shape[1],\n",
    "               dataloader=train_loader,\n",
    "               latent_dims=cfg['mirt_dim'],\n",
    "               hidden_layer_size=cfg['hidden_layer_size2'],\n",
    "               hidden_layer_size2=cfg['hidden_layer_size3'],\n",
    "               qm=Q,\n",
    "               learning_rate=cfg['learning_rate'],\n",
    "               batch_size=data.shape[0]\n",
    "\n",
    "    )\n",
    "else:\n",
    "    raise Exception(\"Invalid model type\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8d862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "trainer.fit(vae)\n",
    "runtime = time.time()-start\n",
    "print(runtime)\n",
    "\n",
    "a_est = vae.decoder.linear.weight.detach().cpu().numpy()[:, 0:cfg['mirt_dim']]\n",
    "d_est = vae.decoder.linear.bias.detach().cpu().numpy()\n",
    "vae = vae.to(device)\n",
    "\n",
    "if cfg['model'] in ['cvae', 'iwae']:\n",
    "    dataset = SimDataset(data, device)\n",
    "    train_loader = DataLoader(dataset, batch_size=data.shape[0], shuffle=False)\n",
    "    data, mask = next(iter(train_loader))\n",
    "    theta_est, _ = vae.encoder(data, mask)\n",
    "elif cfg['model'] in ['idvae', 'vae']:\n",
    "    dataset = SimDataset(data, device)\n",
    "    train_loader = DataLoader(dataset, batch_size=data.shape[0], shuffle=False)\n",
    "    data, mask = next(iter(train_loader))\n",
    "    theta_est, _ = vae.encoder(data)\n",
    "elif cfg['model'] == 'ivae':\n",
    "    theta_est, _ = vae.encoder(vae.data)\n",
    "elif cfg['model'] == 'pvae':\n",
    "    dataset = PartialDataset(data, device)\n",
    "    train_loader = DataLoader(dataset, batch_size=data.shape[0], shuffle=False)\n",
    "    item_ids, ratings, _, _ = next(iter(train_loader))\n",
    "    theta_est, _ = vae.encoder(item_ids, ratings)\n",
    "\n",
    "\n",
    "theta_est = theta_est.detach().cpu().numpy()\n",
    "if cfg['mirt_dim'] == 1:\n",
    "    theta = np.expand_dims(theta, 1)\n",
    "# invert factors for increased interpretability\n",
    "a_est, theta_est = inv_factors(a_est=a_est, theta_est=theta_est, a_true=a)\n",
    "\n",
    "mse_a = f'{MSE(a_est, a)}\\n'\n",
    "mse_d = f'{MSE(d_est, b)}\\n'\n",
    "mse_theta = f'{MSE(theta_est, theta)}\\n'\n",
    "\n",
    "lll = f'{loglikelihood(a_est, d_est, theta_est, data.numpy())}\\n'\n",
    "\n",
    "# print results\n",
    "print(mse_a)\n",
    "print(mse_d)\n",
    "print(mse_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcd499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# plot training loss\n",
    "logs = pd.read_csv(f'logs/simfit/version_0/metrics.csv')\n",
    "plt.plot(logs['epoch'], logs['train_loss'])\n",
    "plt.title('Training loss')\n",
    "plt.savefig(f'./figures/simfit/training_loss.png')\n",
    "\n",
    "\n",
    "# plot binary cross entropy\n",
    "# plt.clf()\n",
    "# plt.plot(logs['epoch'], logs['binary_cross_entropy'])\n",
    "# plt.title('Binary Cross Entropy')\n",
    "# plt.savefig(f'./figures/simfit/binary_cross_entropy.png')\n",
    "# # plot KL divergence\n",
    "# plt.clf()\n",
    "# plt.plot(logs['epoch'], logs['kl_divergence'])\n",
    "# plt.title('KL Divergence')\n",
    "# plt.savefig(f'./figures/simfit/kl_divergence.png')\n",
    "\n",
    "if cfg['mirt_dim'] ==1:\n",
    "     a = np.expand_dims(a, 1)\n",
    "     theta = np.expand_dims(theta, 1)\n",
    "# parameter estimation plot for a\n",
    "for dim in range(cfg['mirt_dim']):\n",
    "    plt.figure()\n",
    "\n",
    "    ai_est = a_est[:,dim]\n",
    "    ai_true = a[:,dim]\n",
    "\n",
    "    mse = MSE(ai_est, ai_true)\n",
    "    plt.scatter(y=ai_est, x=ai_true)\n",
    "    plt.plot(ai_true, ai_true)\n",
    "    #for i, x in enumerate(ai_true):\n",
    "    #    plt.text(ai_true[i], ai_est[i], i)\n",
    "    plt.title(f'Parameter estimation plot: a{dim+1}, MSE={round(mse,4)}')\n",
    "    plt.xlabel('True values')\n",
    "    plt.ylabel('Estimates')\n",
    "    plt.savefig(f'./figures/simfit/param_est_plot_a{dim+1}.png')\n",
    "\n",
    "    # parameter estimation plot for theta\n",
    "    plt.figure()\n",
    "    thetai_est = theta_est[:, dim]\n",
    "    thetai_true = theta[:, dim]\n",
    "    mse = MSE(thetai_est, thetai_true)\n",
    "    plt.scatter(y=thetai_est, x=thetai_true)\n",
    "    plt.plot(thetai_true, thetai_true)\n",
    "    plt.title(f'Parameter estimation plot: theta{dim+1}, MSE={round(mse,4)}')\n",
    "    plt.xlabel('True values')\n",
    "    plt.ylabel('Estimates')\n",
    "    plt.savefig(f'./figures/simfit/param_est_plot_theta{dim+1}.png')\n",
    "\n",
    "# parameter estimation plot for d\n",
    "plt.figure()\n",
    "plt.scatter(y=d_est, x=b)\n",
    "plt.plot(b,b)\n",
    "mse = MSE(d_est, b)\n",
    "plt.title(f'Parameter estimation plot: d, MSE={round(mse,4)}')\n",
    "plt.xlabel('True values')\n",
    "plt.ylabel('Estimates')\n",
    "#plt.savefig(f'./figures/simfit/param_est_plot_d.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
