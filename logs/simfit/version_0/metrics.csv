train_loss,epoch,step
221.28952026367188,24,49
192.1786346435547,49,99
178.69264221191406,74,149
173.36190795898438,99,199
171.509033203125,124,249
170.55128479003906,149,299
169.91746520996094,174,349
169.44561767578125,199,399
169.08120727539062,224,449
168.80462646484375,249,499
168.48788452148438,274,549
168.2165985107422,299,599
167.94505310058594,324,649
167.70977783203125,349,699
167.5452880859375,374,749
167.37831115722656,399,799
167.28280639648438,424,849
167.1238250732422,449,899
167.0248260498047,474,949
166.9006805419922,499,999
166.78790283203125,524,1049
166.68099975585938,549,1099
166.60206604003906,574,1149
166.550048828125,599,1199
166.4567413330078,624,1249
166.39773559570312,649,1299
166.32090759277344,674,1349
166.3234100341797,699,1399
166.28663635253906,724,1449
166.20516967773438,749,1499
166.14810180664062,774,1549
166.11251831054688,799,1599
166.06307983398438,824,1649
166.0311737060547,849,1699
165.98155212402344,874,1749
165.92019653320312,899,1799
165.8946075439453,924,1849
165.86923217773438,949,1899
165.8210906982422,974,1949
165.8123016357422,999,1999
165.74473571777344,1024,2049
165.69801330566406,1049,2099
165.7277374267578,1074,2149
165.68008422851562,1099,2199
165.66099548339844,1124,2249
165.59197998046875,1149,2299
165.5836639404297,1174,2349
165.54981994628906,1199,2399
165.50221252441406,1224,2449
165.4497528076172,1249,2499
165.45809936523438,1274,2549
165.4353790283203,1299,2599
165.42393493652344,1324,2649
165.35145568847656,1349,2699
165.40040588378906,1374,2749
165.36814880371094,1399,2799
165.32342529296875,1424,2849
165.30531311035156,1449,2899
165.2590789794922,1474,2949
165.2695770263672,1499,2999
165.2443084716797,1524,3049
165.24472045898438,1549,3099
165.2323760986328,1574,3149
165.2303466796875,1599,3199
165.20687866210938,1624,3249
165.15713500976562,1649,3299
165.16783142089844,1674,3349
165.1139373779297,1699,3399
165.09298706054688,1724,3449
